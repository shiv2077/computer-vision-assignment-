{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYpr2Mt8x-W4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELC1dx2m36B_",
        "outputId": "53ce258f-bb2c-44d8-d681-edfdfd6f7825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the paths for your training, validation, and test datasets\n",
        "train_dir = '/content/drive/MyDrive/data/sdss_dataset_split/Train'\n",
        "val_dir = '/content/drive/MyDrive/data/sdss_dataset_split/Validation'\n",
        "test_dir = '/content/drive/MyDrive/data/sdss_dataset_split/Test'\n",
        "\n",
        "# Define image size and batch size\n",
        "img_height, img_width = 224, 224\n",
        "batch_size = 32\n",
        "\n",
        "# Load the ResNet50 model without the top layer\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "\n",
        "# Unfreeze the last few layers for fine-tuning\n",
        "for layer in base_model.layers[-4:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Add custom layers on top of the base model\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)  # Added dropout to prevent overfitting\n",
        "x = Dense(3, activation='softmax')(x)  # 3 classes: 5, 6, 7\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aG4ZrRW3NTG",
        "outputId": "65f76d22-355d-41cb-8146-809881b78435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the final model\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model with a lower learning rate\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Data augmentation and data generators for loading images\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,  # Added vertical flip\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Learning rate reduction on plateau\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
        "\n",
        "# Checkpoint to save the best model\n",
        "checkpoint_filepath = '/content/drive/MyDrive/best_resnet_model.keras'\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfwNU2Qc3Pw9",
        "outputId": "bbb876d1-6d1c-45c3-84af-77783beefb6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5240 images belonging to 3 classes.\n",
            "Found 650 images belonging to 3 classes.\n",
            "Found 650 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=30,  # Increased number of epochs\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[reduce_lr, model_checkpoint]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgwxUpW-3Ti8",
        "outputId": "8a0624cd-ef62-4448-ee5b-715b30547722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15s/step - accuracy: 0.4668 - loss: 1.6120 \n",
            "Epoch 1: val_accuracy improved from -inf to 0.40462, saving model to /content/drive/MyDrive/best_resnet_model.keras\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3161s\u001b[0m 18s/step - accuracy: 0.4673 - loss: 1.6092 - val_accuracy: 0.4046 - val_loss: 3.1433 - learning_rate: 1.0000e-04\n",
            "Epoch 2/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 0.6757 - loss: 0.7569\n",
            "Epoch 2: val_accuracy improved from 0.40462 to 0.40615, saving model to /content/drive/MyDrive/best_resnet_model.keras\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 445ms/step - accuracy: 0.6758 - loss: 0.7568 - val_accuracy: 0.4062 - val_loss: 2.1750 - learning_rate: 1.0000e-04\n",
            "Epoch 3/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.7540 - loss: 0.6385\n",
            "Epoch 3: val_accuracy did not improve from 0.40615\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 402ms/step - accuracy: 0.7540 - loss: 0.6385 - val_accuracy: 0.2815 - val_loss: 1.9977 - learning_rate: 1.0000e-04\n",
            "Epoch 4/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.7795 - loss: 0.5611\n",
            "Epoch 4: val_accuracy did not improve from 0.40615\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 404ms/step - accuracy: 0.7795 - loss: 0.5612 - val_accuracy: 0.4046 - val_loss: 2.2062 - learning_rate: 1.0000e-04\n",
            "Epoch 5/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.7864 - loss: 0.5413\n",
            "Epoch 5: val_accuracy did not improve from 0.40615\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 398ms/step - accuracy: 0.7863 - loss: 0.5415 - val_accuracy: 0.2815 - val_loss: 1.2018 - learning_rate: 1.0000e-04\n",
            "Epoch 6/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.8055 - loss: 0.5164\n",
            "Epoch 6: val_accuracy improved from 0.40615 to 0.60154, saving model to /content/drive/MyDrive/best_resnet_model.keras\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 432ms/step - accuracy: 0.8055 - loss: 0.5163 - val_accuracy: 0.6015 - val_loss: 0.9823 - learning_rate: 1.0000e-04\n",
            "Epoch 7/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.8195 - loss: 0.4756\n",
            "Epoch 7: val_accuracy improved from 0.60154 to 0.67077, saving model to /content/drive/MyDrive/best_resnet_model.keras\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 438ms/step - accuracy: 0.8195 - loss: 0.4756 - val_accuracy: 0.6708 - val_loss: 0.8445 - learning_rate: 1.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.8266 - loss: 0.4551\n",
            "Epoch 8: val_accuracy improved from 0.67077 to 0.73692, saving model to /content/drive/MyDrive/best_resnet_model.keras\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 439ms/step - accuracy: 0.8266 - loss: 0.4551 - val_accuracy: 0.7369 - val_loss: 0.5946 - learning_rate: 1.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 0.8278 - loss: 0.4251\n",
            "Epoch 9: val_accuracy improved from 0.73692 to 0.82154, saving model to /content/drive/MyDrive/best_resnet_model.keras\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 444ms/step - accuracy: 0.8278 - loss: 0.4251 - val_accuracy: 0.8215 - val_loss: 0.4477 - learning_rate: 1.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 0.8432 - loss: 0.4221\n",
            "Epoch 10: val_accuracy did not improve from 0.82154\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 408ms/step - accuracy: 0.8431 - loss: 0.4222 - val_accuracy: 0.8077 - val_loss: 0.6056 - learning_rate: 1.0000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.8412 - loss: 0.4294\n",
            "Epoch 11: val_accuracy did not improve from 0.82154\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 401ms/step - accuracy: 0.8412 - loss: 0.4294 - val_accuracy: 0.7815 - val_loss: 0.5466 - learning_rate: 1.0000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.8456 - loss: 0.4004\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.82154\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 399ms/step - accuracy: 0.8457 - loss: 0.4004 - val_accuracy: 0.7754 - val_loss: 0.5551 - learning_rate: 1.0000e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.8668 - loss: 0.3502\n",
            "Epoch 13: val_accuracy improved from 0.82154 to 0.84462, saving model to /content/drive/MyDrive/best_resnet_model.keras\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 432ms/step - accuracy: 0.8668 - loss: 0.3501 - val_accuracy: 0.8446 - val_loss: 0.4023 - learning_rate: 5.0000e-05\n",
            "Epoch 14/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.8867 - loss: 0.3237\n",
            "Epoch 14: val_accuracy improved from 0.84462 to 0.85231, saving model to /content/drive/MyDrive/best_resnet_model.keras\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 442ms/step - accuracy: 0.8866 - loss: 0.3237 - val_accuracy: 0.8523 - val_loss: 0.3696 - learning_rate: 5.0000e-05\n",
            "Epoch 15/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.8836 - loss: 0.3187\n",
            "Epoch 15: val_accuracy did not improve from 0.85231\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 402ms/step - accuracy: 0.8836 - loss: 0.3186 - val_accuracy: 0.8323 - val_loss: 0.4376 - learning_rate: 5.0000e-05\n",
            "Epoch 16/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.8863 - loss: 0.3084\n",
            "Epoch 16: val_accuracy did not improve from 0.85231\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 403ms/step - accuracy: 0.8863 - loss: 0.3084 - val_accuracy: 0.8092 - val_loss: 0.4906 - learning_rate: 5.0000e-05\n",
            "Epoch 17/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.8976 - loss: 0.2802\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.85231\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 403ms/step - accuracy: 0.8975 - loss: 0.2803 - val_accuracy: 0.8308 - val_loss: 0.4288 - learning_rate: 5.0000e-05\n",
            "Epoch 18/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.9120 - loss: 0.2589\n",
            "Epoch 18: val_accuracy did not improve from 0.85231\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 406ms/step - accuracy: 0.9119 - loss: 0.2589 - val_accuracy: 0.8400 - val_loss: 0.4441 - learning_rate: 2.5000e-05\n",
            "Epoch 19/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - accuracy: 0.9075 - loss: 0.2407\n",
            "Epoch 19: val_accuracy improved from 0.85231 to 0.85846, saving model to /content/drive/MyDrive/best_resnet_model.keras\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 439ms/step - accuracy: 0.9075 - loss: 0.2408 - val_accuracy: 0.8585 - val_loss: 0.3697 - learning_rate: 2.5000e-05\n",
            "Epoch 20/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 0.9090 - loss: 0.2438\n",
            "Epoch 20: val_accuracy did not improve from 0.85846\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 409ms/step - accuracy: 0.9089 - loss: 0.2438 - val_accuracy: 0.8554 - val_loss: 0.3576 - learning_rate: 2.5000e-05\n",
            "Epoch 21/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.9126 - loss: 0.2407\n",
            "Epoch 21: val_accuracy improved from 0.85846 to 0.86308, saving model to /content/drive/MyDrive/best_resnet_model.keras\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 437ms/step - accuracy: 0.9126 - loss: 0.2406 - val_accuracy: 0.8631 - val_loss: 0.3433 - learning_rate: 2.5000e-05\n",
            "Epoch 22/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.9103 - loss: 0.2351\n",
            "Epoch 22: val_accuracy did not improve from 0.86308\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 404ms/step - accuracy: 0.9103 - loss: 0.2352 - val_accuracy: 0.8615 - val_loss: 0.3806 - learning_rate: 2.5000e-05\n",
            "Epoch 23/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.9211 - loss: 0.2106\n",
            "Epoch 23: val_accuracy did not improve from 0.86308\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 400ms/step - accuracy: 0.9211 - loss: 0.2106 - val_accuracy: 0.8508 - val_loss: 0.3755 - learning_rate: 2.5000e-05\n",
            "Epoch 24/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - accuracy: 0.9200 - loss: 0.2133\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.86308\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 417ms/step - accuracy: 0.9200 - loss: 0.2132 - val_accuracy: 0.8538 - val_loss: 0.4103 - learning_rate: 2.5000e-05\n",
            "Epoch 25/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.9253 - loss: 0.1994\n",
            "Epoch 25: val_accuracy did not improve from 0.86308\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 405ms/step - accuracy: 0.9253 - loss: 0.1995 - val_accuracy: 0.8615 - val_loss: 0.3578 - learning_rate: 1.2500e-05\n",
            "Epoch 26/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.9270 - loss: 0.1864\n",
            "Epoch 26: val_accuracy did not improve from 0.86308\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 405ms/step - accuracy: 0.9270 - loss: 0.1865 - val_accuracy: 0.8569 - val_loss: 0.3593 - learning_rate: 1.2500e-05\n",
            "Epoch 27/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.9299 - loss: 0.1783\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.86308\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 402ms/step - accuracy: 0.9299 - loss: 0.1784 - val_accuracy: 0.8631 - val_loss: 0.3796 - learning_rate: 1.2500e-05\n",
            "Epoch 28/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.9382 - loss: 0.1693\n",
            "Epoch 28: val_accuracy did not improve from 0.86308\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 404ms/step - accuracy: 0.9382 - loss: 0.1693 - val_accuracy: 0.8615 - val_loss: 0.3722 - learning_rate: 6.2500e-06\n",
            "Epoch 29/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.9275 - loss: 0.1789\n",
            "Epoch 29: val_accuracy did not improve from 0.86308\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 402ms/step - accuracy: 0.9276 - loss: 0.1789 - val_accuracy: 0.8615 - val_loss: 0.3808 - learning_rate: 6.2500e-06\n",
            "Epoch 30/30\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - accuracy: 0.9363 - loss: 0.1583\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
            "\n",
            "Epoch 30: val_accuracy improved from 0.86308 to 0.86615, saving model to /content/drive/MyDrive/best_resnet_model.keras\n",
            "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 442ms/step - accuracy: 0.9363 - loss: 0.1583 - val_accuracy: 0.8662 - val_loss: 0.3902 - learning_rate: 6.2500e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f'Test accuracy: {test_acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2CcqfPS3U-Z",
        "outputId": "24f65935-4124-4c77-f839-fbc306e410a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m401s\u001b[0m 20s/step - accuracy: 0.8842 - loss: 0.3059\n",
            "Test accuracy: 0.8769230842590332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on new data\n",
        "predictions = model.predict(test_generator)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y2myzb-6lIz",
        "outputId": "a8b7dcce-9c00-46d3-cbfa-306ad470a6b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 257ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the final model with the .keras extension\n",
        "final_model_filepath = '/content/drive/MyDrive/final_resnet_model.keras'\n",
        "model.save(final_model_filepath)"
      ],
      "metadata": {
        "id": "IKFT71lc6lPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('/content/drive/MyDrive/final_resnet_model.keras')"
      ],
      "metadata": {
        "id": "Q_sqAM2yQyHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Define image size expected by the model\n",
        "img_height, img_width = 224, 224\n",
        "\n",
        "# Load and preprocess the image\n",
        "img_path = '/content/drive/MyDrive/data/sdss_dataset_split/Test/6/image_0_class_6.jpg'\n",
        "img = image.load_img(img_path, target_size=(img_height, img_width))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "img_array = img_array / 255.0  # Normalize pixel values to [0, 1]\n"
      ],
      "metadata": {
        "id": "_er_Dlk6RA-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "# Get the predicted class\n",
        "predicted_class = np.argmax(predictions, axis=1)\n",
        "print(f'Predicted class index: {predicted_class[0]}')\n"
      ],
      "metadata": {
        "id": "DT56J7OkRBE-",
        "outputId": "d9c0181b-db71-4fce-fbff-56c0f4f54a7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "Predicted class index: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class labels\n",
        "class_labels = ['Class 5', 'Class 6', 'Class 7']\n",
        "\n",
        "# Map the index to label\n",
        "predicted_label = class_labels[predicted_class[0]]\n",
        "print(f'Predicted class label: {predicted_label}')\n"
      ],
      "metadata": {
        "id": "24dAONC9RBKr",
        "outputId": "dadcf0fd-e521-490b-ada3-4482ee978ff6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class label: Class 6\n"
          ]
        }
      ]
    }
  ]
}